"test_id","feature_area","test_type","test_level","priority","automation_candidate","automation_roi","test_description","business_risk","technical_complexity","preconditions","test_steps","expected_result","test_data_needs","tools_required","estimated_effort_hours","automation_effort_hours","maintenance_effort_annual","dependencies","environment_requirements","success_criteria","failure_impact","regression_frequency","data_setup_complexity","cleanup_requirements","security_considerations","performance_expectations","accessibility_requirements"
"TEST-AUTH-001","User Authentication","Functional","Integration","Critical","true","High","Verify user can log in with valid credentials, their role is correctly identified, and a session is established.","High - Authentication failure blocks all user access.","Medium","User account 'test_admin' (Admin role) and 'test_tech' (Technician role) exist and are active in PostgreSQL DB. BCrypt hashing service is functional.","1. Instantiate AuthenticationService with real DbContext. 2. Call LoginAsync with 'test_admin' and correct password. 3. Verify result is success and returned session object contains 'Administrator' role. 4. Call LoginAsync with 'test_tech' and correct password. 5. Verify result is success and session contains 'Technician' role. 6. Call LoginAsync with 'test_admin' and incorrect password. 7. Verify result is failure.","AuthenticationService correctly validates credentials against the database and returns a session object with the correct user role.","Pre-provisioned user accounts with known passwords and roles in a test database.","xUnit, Testcontainers (for PostgreSQL), Moq (for non-DB dependencies), EF Core","8","12","4","TASK-005 (Authentication Service)","CI environment with Docker to run a PostgreSQL instance.","100% test pass rate for all login scenarios (valid, invalid, disabled). Login response within 500ms.","Critical - Users cannot access the system; RBAC fails.","Every commit to the authentication module.","Medium - Requires scripting to seed the test database.","Test database instance is destroyed after test run.","Test ensures generic error messages are returned to prevent user enumeration.","Login completes within 500ms under test conditions.","N/A for integration test."
"TEST-INGEST-001","DICOM Network Services","Functional","System/E2E","Critical","true","High","Verify the end-to-end asynchronous ingestion of a DICOM study via C-STORE, from reception to database persistence.","Critical - Failure to ingest data means loss of clinical information.","High","The full application stack is running: Windows Service (with SCP listener), RabbitMQ, and PostgreSQL.","1. Use DCMTK's storescu tool to send a multi-file DICOM study to the application's SCP listener. 2. Verify storescu receives a DICOM success status (0x0000). 3. Monitor RabbitMQ admin UI to confirm a message is published to the 'dicom_store_queue'. 4. Verify the message is consumed and removed from the queue. 5. Query the PostgreSQL database to confirm records for Patient, Study, Series, and Images have been created. 6. Check the configured file storage path to verify the DICOM files exist in the correct hierarchical folder structure.","The DICOM study is successfully received, and its metadata and files are correctly and transactionally persisted in the system.","A valid, multi-file DICOM test study (e.g., a CT or MR series).","DCMTK (storescu), RabbitMQ Management UI, PostgreSQL client (psql or DBeaver), Automated E2E test script (C#)","16","30","10","TASK-026, TASK-027, TASK-028","Staging environment with all services configured and networked.","100% of valid test studies ingested successfully within 60 seconds of send completion. No data loss.","Critical - System cannot perform its core function of receiving data.","Every release candidate build.","Low","Database records and stored files for the test study must be deleted.","Test with DICOM files containing PHI to ensure it is handled correctly (e.g., encrypted in DB).","SCP should handle at least 10 concurrent associations without dropping connections (REQ-1-078).","N/A for E2E test."
"TEST-PERF-001","DICOM Viewer","Performance","System/E2E","High","true","Medium","Measure the performance of loading a large DICOM study and the responsiveness of the interactive Window/Level tool, ensuring it meets requirements and is not subject to memory leaks.","High - A slow or unstable viewer makes the application unusable for clinical work (RISK-001).","High","WPF client application is installed on a machine meeting recommended hardware specs. A large (500MB+) DICOM study is available.","1. Start performance profiler (e.g., dotTrace). 2. Start the client application and measure memory usage. 3. Start a timer and open the large DICOM study. 4. Stop timer when the low-res preview is first displayed. 5. Repeatedly (100 times) open and close the study, measuring memory usage after each cycle to detect leaks. 6. With the study open, programmatically simulate rapid mouse movements for the WW/WL tool for 60 seconds, measuring average CPU usage and UI thread responsiveness.","Study load time is < 3 seconds (REQ-1-077). UI responsiveness is < 500ms. Memory usage remains stable (no leaks) after repeated open/close cycles.","A large, multi-frame DICOM study (>500 MB).","Automated UI testing framework (Appium/WinAppDriver), Performance Profiler (JetBrains dotTrace/dotMemory), Custom C# test harness.","24","40","15","US-014 fully implemented.","Dedicated performance testing hardware matching recommended customer specs.","Meets all performance targets from REQ-1-077. Memory growth < 5% after 100 open/close cycles.","High - Poor user experience, potential application crashes, failure to meet core NFRs.","On every major change to the viewer and before every major release.","Medium - Requires specific large datasets.","N/A","N/A","As per REQ-1-077.","N/A for this test."
"TEST-SEC-001","Security & Compliance","Security","Integration","Critical","true","High","Verify that editing DICOM metadata is correctly logged in the audit trail, including user ID, timestamp, old value, and new value, satisfying HIPAA requirements.","Critical - Failure to audit PHI changes is a major HIPAA violation (RISK-002).","Medium","A study exists in the database. An Administrator user is authenticated.","1. As Admin, programmatically initiate a DICOM metadata edit on a test study (e.g., change PatientName tag (0010,0010)). 2. Save the change. 3. Query the 'AuditLog' table in the database. 4. Verify a new record exists for the event. 5. Inspect the 'details' JSONB column of the new record. 6. Confirm it contains the Admin's UserID, the correct DICOM tag, the original value, and the new value.","A compliant, detailed audit trail entry is created for every modification of DICOM metadata.","A test DICOM study and an Admin user account.","xUnit, EF Core, Testcontainers (PostgreSQL).","6","10","3","US-017, US-031.","CI environment with Docker to run a PostgreSQL instance.","100% of metadata changes are logged with all required fields (user, timestamp, tag, old/new value).","Critical - Compliance failure, inability to perform security investigations.","Every commit to the metadata editing or audit modules.","Medium","Test database is destroyed after test run.","The audit trail itself must be immutable and protected from tampering.","Audit log write should be part of the transaction and complete within 50ms.","N/A."
"TEST-REL-001","Core Architecture","Functional (Reliability)","Integration","High","true","High","Verify that a 'poison message' in the DICOM ingestion queue is correctly moved to the Dead-Letter Queue (DLQ) after a configured number of failed processing attempts.","High - A poison message can block all subsequent data ingestion, causing a system-wide outage (RISK-005).","Medium","RabbitMQ is configured with a main queue and a DLQ. The ingestion consumer service is running with a retry policy of 3.","1. Programmatically publish a malformed message (e.g., missing a required metadata field) to the 'dicom_store_queue'. 2. Monitor the RabbitMQ management UI. 3. Verify the message is delivered, rejected, and redelivered 3 times. 4. After the third failure, verify the message is removed from the main queue. 5. Verify the message now exists in the configured 'dicom_store_dlq'. 6. Verify an alert is triggered (e.g., an error is logged, an email is sent).","The system robustly handles unprocessable messages by routing them to a DLQ, preventing queue blockage.","A serialized message object that is guaranteed to cause a processing exception.","C# RabbitMQ client, xUnit, RabbitMQ Management UI.","8","14","5","TASK-029.","CI environment with a running RabbitMQ instance.","100% of poison messages are routed to the DLQ after exhausting retries.","High - Potential for complete halt of asynchronous processing.","Every release candidate build.","Low","Queues should be purged after the test run.","N/A","N/A","N/A"